\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{Light Field Video Compression using 5-D Approximate DCT\\
%{\footnotesize \textsuperscript{*}Note: Sub-titles are not captured in Xplore and should not be used}
%\thanks{Identify applicable funding agency here. If none, delete this.}
}

\author{\IEEEauthorblockN{1\textsuperscript{st} S. Braveenan}
\IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
\textit{name of organization (of Aff.)}\\
City, Country \\
email address or ORCID}
}

\maketitle

\begin{abstract}
A low-complexity algorithm is proposed to achieve compression of five-dimensional (5-D) Light Field Videos from
camera/lenslet arrays. The proposed system employs the 5-D, extension of the four-dimensional (4-D) \(8\times 8\times 8\times 8\) approximate discrete cosine transform (ADCT) that has already appeared in the literature. Motivated by the partial separability of the multidimensional
spectrum of Light Field Videos, the proposed 5-D ADCT is obtained by cascading 2-D inter-view, 2-D intra-view with 1-D time transform stages. Software simulations are provided to confirm the performance
of the 5-D ADCT based compression. Data sets with different characteristics are applied to system and could get 49.6 dB average PSNR and 0.98 average SSIM for sub aperture images. 

\end{abstract}

\begin{IEEEkeywords}

\end{IEEEkeywords}

\section{Introduction}
Light in space can be represented as seven-dimensional(7-D) function \(l(x,y,z,\theta,\phi,\lambda,t)\) where \(x,y,z)\) indicates spatial, \(\theta,\phi)\) indicates angular, \(\lambda\) indicates frequency and \(t\) indicates time. Normally Light rays of Light Field Videos do not change along direction of propagation. So one dimension in space can be removed Frequency \(\lambda\) is replaced with three colour channels and all three colour channel Light Field Videos are treated as independently. After these modifications, Light Field Video is represented as five-dimensional(5-D) function \(l(x,y,\theta,\phi,t)\). To simplify Light Field Video representation, Each frame in Light Field Video can be represented in two parallel planes parameterization. Here one plane is called as camera plane XY and other plane is image plane UV. Distance D between these 2 planes are assumed as focal length of camera. Now Light Field Video is represented as \(l(x,y,u,v,t)\). Where \((x,y)\) are spatial dimension and \((u,v)\) are angular dimensions.

Light Field technology widely applies in Computer vision due to additional post capture processing capabilities such as Image refocusing, Depth filtering, Distance measurement, Changing lighting conditions etc. However the large volume of data captured in Light Field Video. So it is difficult to process in real-time, mobile or web-based applications, where limited storage and transmission bandwidth requirements are needed to process. Compressing Light Field Videos in fast and low-complexity before processing eliminates difficulties mentioned earlier.

In this work, we propose a 5-D Light Field Video compression system, which is suitable for real-time compression of 5-D Light Field Videos, using 5-D type 2 discrete cosine transform (DCT) which has energy compaction property and widely used in data compression applications. The proposed system tests with approximate DCTs (ADCT) which have appeared in literature and are hardware efficient than exact DCT. By using 2-D partial separability, 4-D ADCT is obtained as a cascade of two 2-D ADCTs and one 1-D ADCT. Here first 2-D ADCT refers as intra-view transform where operations are done within Sub Aperture Images of particular frame, second 2-D ADCT refers as inter-view transform where operations are done across Sub Aperture Images of particular frame and 1-D ADCT operations are done across frames. Then obtained 5-D ADCT of a Light Field Video is subsequently treated as a collection of 5-D hyper-cubes of size \((8\times8\times8\times8\times8)\) and 5-D quantization happens, using constant \((8\times8\times8\times8\times8)\) matrix, on it to obtain compressed Light Field Video in 5-D DCT domain. Finally different data sets and different ADCT matrices are used and those PSNR values and SSIM values are compared in Performance Analysis part.


\section{Related Work In LFV Compression}


\section{Proposed 5-D ADCT Based LFV Compression}
Input to the proposed 5-D ADCT based Light Field Video Compression system is Light Field Video \(l(n)\), Here \(n \equiv (n_x,n_y,n_u,n_v,n_t) \in \mathbb{N}^5 \) denotes 5-D discrete spatial domain, \(n_x, n_y\) denotes point in camera plane, \(n_u, n_v\) denotes point in image plane and \(n_t\) denotes point in time axis. Based on standard two plane parameterization, size of Light Field Video is assumed as \((N_x,N_y,N_u,N_v,N_t)\). This size indicates there are \(N_x \times N_y\) SAIs, size of each SAI is \(N_u \times N_v\) pixels and \(N_t\) indicates number of frames in Light Field Video. Compression has been done in each channel separately.

First step is partitioning all SAIs of particular time into \(8 \times 8\) blocks and applying Normalized 2-D DCT-2 on it. Let \(X\) be extracted \(8 \times 8\) block, whose entries are given by \(x[n_1,n_2]\) for \(n_1,n_2 = 1,2,...8\). 2-D DCT transformation of \(X\) is \(Y\), whose entries are given by:
\begin{multline*}
y[k_1,k_2] = a_N[k_1] \cdot a_N[k_2] \cdot \sum_{n_1=0}^{N-1} \sum_{n_2=0}^{N-1} x[n_1,n_2] \cdot \\ 
\cos{\left(\frac{\pi k_1(2n_1+1)}{2N}\right)} \cdot \cos{\left(\frac{\pi k_2(2n_2+1)}{2N}\right)}
\end{multline*}
where 
\[
    a_N[k] = \frac{1}{\sqrt{N}}
\begin{cases}
    1,& k_i = 0\\
    \sqrt{2},& k_i = 1,2,..,N-1
\end{cases}
\]
Here N = 8.
To solve equations efficiently, we can express this as:
\[Y = C_N \cdot X \cdot C_N^T \]
\(C_N\) entries are given by:
\[C_N[k,n] = a_N[k] \cdot \cos{\left(\frac{\pi k(2n+1)}{2N}\right)}\]
To achieve both null multiplier complexity and reduce adder complexity, instead of ideal DCT matrix \(C_N\), we use approximate DCT matrix \(\hat{C}_N\), which can be written as \(\hat{C}_N  = D_N \cdot T_N\). Here \(D_N\) is diagonal matrix with irrational numbers. This ADCT operation is repeated for all \(8 \times 8\) blocks in all SAIs for particular time. \(N_x \times N_y \times N_u/8 \times N_v/8 \times N_t\) no of operations are needed to complete intra-view ADCT transformation on entire Light Field Video and leads to create mixed domain 5-D signal \(L_1(n_x,n_y,k_u,k_v,n_t)\).

Next creating \(N_x\times N_y\) view points blocks from \(L_1(n_x,n_y,k_u,k_v,n_t)\) by changing pixel point across SAIs of particular time. Then partition that into \(8 \times 8\) blocks and apply Normalized 2-D DCT-2 on it. As mentioned earlier, To reduce complexity use Approximate DCT matrix \(\hat{C}_N\).This ADCT operation is repeated for all \(8 \times 8\) blocks across all SAIs for particular time. \((N_x/8 \times N_y/8 \times N_u \times N_v \times N_t)\) no of operations are needed to complete inter-view ADCT transformation on entire Light Field Video and leads to create mixed domain 5-D signal \(L_2(k_x,k_y,k_u,k_v,n_t)\).

Next take points along time axis from \(L_2(k_x,k_y,k_u,k_v,n_t)\) for particular view point and pixel point. Then break that into dimension of \(8 \times 1\) vectors and apply Normalized 1-D DCT-2 on it. Let \textbf{x} be extracted \(8 \times 1\) vector, whose entries are given by \(x[n]\) for \(n = 1,2,...8\). 1-D DCT transformation of \textbf{x} is \textbf{y}, whose entries are given by:
\[y[k] = a_N[k] \cdot \sum_{n=0}^{N-1} x[n] \cdot \cos{\left(\frac{\pi k(2n+1)}{2N}\right)} \]
where 
\[
    a_N[k] = \frac{1}{\sqrt{N}}
\begin{cases}
    1,& k_i = 0\\
    \sqrt{2},& k_i = 1,2,..,N-1
\end{cases}
\]
Here N = 8.
To solve equations efficiently, we can express this as:
\[Y = C_N \cdot X \]
\(C_N\) entries are given by:
\[C_N[k,n] = a_N[k] \cdot \cos{\left(\frac{\pi k(2n+1)}{2N}\right)}\]
To reduce complexity, we can use approximate DCT matrix \(\hat{C}_N\) instead of ideal DCT matrix \(C_N\).This ADCT operation is repeated for all \(8 \times 1\) vectors along time axis for particular view point and pixel point. \(N_x \times N_y \times N_u \times N_v \times N_t/8\) no of operations are needed to complete 1-D ADCT transformation on entire Light Field Video and create fully transformed 5-D signal \(L(k_x,k_y,k_u,k_v,k_t)\).

Next apply 5-D Quantization on \(L(\textbf{k})\) to discard high frequency components. \(8 \times 8 \times 8 \times 8 \times 8\) constant value matrix \(Q(k)\) is used in Quantization process. Output of Quantization process is expressed as:
\[L_q(k) = round \left( \frac{L(k)}{Q(k)} \right) \cdot Q(k)\]
where both the division and multiplication of the matrices are element wise. After quantization process, ADCT coefficients higher than threshold value are only retained, leading to lossy Light Field Video compression.

\section{Performance Analysis}
To measure performance of Light Field Video compression, three Light Field Videos were used : Car, David, Toy. All three Light Field Videos were made from \(15\times15\) views of videos. For our processing \(8\times8\) views were taken and all SAIs are in YUV420 format. Table \ref{table:DatasetsSpecification} summarizes size, minimum and maximum value of each data set channel.

\begin{table}
\begin{center}
\caption{Data Set Specification}
\label{table:DatasetsSpecification}
\begin{tabular}{|c c c c c|} 
 \hline
 Dataset & Channel & Size & Min & Max \\ [0.5ex] 
 \hline\hline
 Car & U & \(8\times8\times176\times256\times24\) & 25 & 181\\
 \hline
 & V & \(8\times8\times176\times256\times24\) & 80 & 193\\
 \hline
 & Y & \(8\times8\times352\times512\times24\) & 3 & 255\\
 \hline\hline
 David & U & \(8\times8\times160\times240\times24\) & 49 & 122\\
 \hline
 & V & \(8\times8\times160\times240\times24\) & 107 & 151\\
 \hline 
 & Y & \(8\times8\times320\times480\times24\) & 43 & 229\\
 \hline\hline
 Toy & U & \(8\times8\times160\times240\times24\) & 3 & 160 \\ 
 \hline
 & V & \(8\times8\times160\times240\times24\) & 50 & 224 \\ 
 \hline
 & Y & \(8\times8\times320\times480\times24\) & 12 & 255\\ [0.5ex] 
 \hline
\end{tabular}
\end{center}
\end{table}

Quality of compressed Light Field Video is measured by using Peak
Signal to Noise Ratio (PSNR) and Structural Similarity Index for Measuring image quality (SSIM) of each SAI. The PSNR between the original SAI A and the reconstructed SAI A’ is computed as follows:
\[PSNR = 10\log_{10}\left( \frac{2^n - 1}{MSE} \right)\]
Where n is no of bits in SAI and MSE between the two M×N SAIs A and A’ is given by:
\[MSE = \left(\frac{1}{M\times N} \right)\sum_{i=0}^{M-1} \sum_{j=0}^{N-1}(A(i,j)-A'(i,j))^2\]
The SSIM between the original SAI A and the reconstructed SAI A’ is computed as follows:
\[SSIM = \frac{(2\mu_A\mu_{A'}+C_1)(2\sigma_{AA'}+C_2)}{(\mu_A^2+\mu_{A'}^2+C_1)(\sigma_A^2+\sigma_{A'}^2+C_2)}\]
Where \(\mu_A,\mu_{A'},\sigma_A,\sigma_{A'},,\sigma_{AA'}\) are local means, standard deviations, and cross covariance for SAIs A, A'. The PSNR and SSIM for Light Field Video are computed by averaging the PSNRs and SSIMs of SAIs individually. The \(SSIM_{YCbCr}\) is computed using only the luminance component (Y). But \(PSNR_{YCbCr}\) is computed by using \(PSNR_Y, PSNR_{Cb}\) and \(PSNR_{Cr}\) as follows:
\[PSNR_{YCbCr} = \frac{6*PSNR_Y + PSNR_{Cb} + PSNR_{Cr}}{8}\]

\begin{figure*}
\begin{center}
\includegraphics[width=\textwidth]{results/bppVSpsnr.jpg}
\caption{PSNR vs Compression rate on different ADCT algorithms Exact DCT, BAS-2008, BAS-2011 for parameter 0, BAS-2011 for parameter 1, CB-2011, Modified CB-2011 and PMC 2014 in 5-D domain for data set (a) Car (b) David (c) Toy. (d) Comparing PSNR vs Compression rate for different data sets on exact DCT}
\label{fig:bppvspsnr}
\end{center}
\end{figure*}

In figure \ref{fig:bppvspsnr}(a)-(c), PSNR is plotted against bits per pixel for different ADCT algorithms. When decreasing compressed Light Field Video bits per pixel, PSNR is also decreasing and at one point it is converging. All 7 PSNR vs Compression rate graphs are nearly same for all 3 data sets. Figure \ref{fig:bppvspsnr}(d) explains PSNR vs Compression rate  graphs for different data sets. For data set Car and Toy, PSNR converges near to 41dB and bits per pixel values starts at near to 0.6. For data set David, PSNR converges near to 45dB and bits per pixel values starts at near to 0.3. As explained in Table \ref{table:DatasetsSpecification}, data set David has small range values than other data sets. This is the reason for that particular data set only getting better PSNR values for small Compression rate  values too.

\begin{figure*}
\begin{center}
\includegraphics[width=\textwidth]{results/bppVSssim.jpg}
\caption{SSIM vs Compression rate on different ADCT algorithms Exact DCT, BAS-2008, BAS-2011 for parameter 0, BAS-2011 for parameter 1, CB-2011, Modified CB-2011 and PMC 2014 in 5-D domain for data set (a) Car (b) David (c) Toy. (d) Comparing SSIM vs Compression rate for different data sets on exact DCT}
\label{fig:bppvsssim}
\end{center}
\end{figure*}

In figure \ref{fig:bppvsssim}(a)-(c), SSIM is plotted against Compression rate  for different ADCT algorithms. All 7 SSIM vs Compression rate  graphs are nearly same for all 3 data sets. From these, assumption can be taken as final outputs will not be differed when using different ADCT matrices. Figure \ref{fig:bppvspsnr}(d) explains SSIM vs Compression rate  graphs for different data sets. Here none of the values are less than 0.9. From these, assumption can be taken as compression does not loose information that much. 

\begin{table}
\begin{center}
\caption{Quantization}
\label{table:qval}
\begin{tabular}{|c|c|c|c|c|} 
 \hline
 \shortstack{\\Quantization \\ value} & \shortstack{\\Compression \\ rate [bpp]}  & PSNR [dB] & SSIM & \shortstack{\\Energy \\ retained} \\ [0.5ex] 
 \hline\hline
 1 & 1.33 & 62.32 & 1 & 1\\
 \hline
 3 & 0.47 & 55.26 & 0.99 & 1\\
 \hline
 5 & 0.28 & 53.53 & 0.99 & 1\\
 \hline
 7 & 0.2 & 52.41 & 0.99 & 1\\
 \hline
 10 & 0.14 & 51.26 & 0.99 & 0.99\\
 \hline 
 15 & 0.09 & 50.06 & 0.98 & 0.99\\
 \hline
 25 & 0.06 & 48.76 & 0.98 & 0.98 \\ 
 \hline
 35 & 0.04 & 48.06 & 0.97 & 0.97 \\ 
 \hline
 50 & 0.04 & 47.44 & 0.97 & 0.96\\ 
 \hline
 80 & 0.03 & 46.67 & 0.97 & 0.95\\
 \hline 
 100 & 0.03 & 46.31 & 0.97 & 0.95\\
 \hline
 120 & 0.03 & 45.97 & 0.96 & 0.95 \\ 
 \hline
 150 & 0.03 & 45.65 & 0.96 & 0.94 \\ 
 \hline
 180 & 0.03 & 45.25 & 0.96 & 0.94\\  
 \hline
 200 & 0.03 & 44.99 & 0.96 & 0.94\\ [0.5ex] 
 \hline
\end{tabular}
\end{center}
\end{table}

Table \ref{table:qval} explains when changing value in constant quantization matrix how compression rate, PSNR, SSIM, energy retained are changing. For this experiment Y channel of data set David is selected. When you are increasing value, at one point retained energy rate is reduced but compression rate, PSNR and SSIM converge. 


\section{Conclusion}



\begin{thebibliography}{00}
\bibitem{b1} U. S. Potluri, A. Madanayake, R. J. Cintra, F. M. Bayer, S. Kulasekera, and A. Edirisuriya, “Improved 8-point Approximate DCT for Image and Video Compression Requiring Only 14 Additions,” IEEE Trans. Circuits Syst. I, Reg. Papers, vol. 61, no. June, pp. 1727–1740, jun 2014.

\end{thebibliography}


\end{document}
