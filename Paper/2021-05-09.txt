\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{Light Field Video Compression using 5-D Approximate DCT\\
%{\footnotesize \textsuperscript{*}Note: Sub-titles are not captured in Xplore and should not be used}
%\thanks{Identify applicable funding agency here. If none, delete this.}
}

\author{\IEEEauthorblockN{1\textsuperscript{st} S. Braveenan}
\IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
\textit{name of organization (of Aff.)}\\
City, Country \\
email address or ORCID}
}

\maketitle

\begin{abstract}
A low-complexity algorithm is proposed to achieve compression of five-dimensional (5-D) Light Field Videos from
camera/lenslet arrays. The proposed system employs the 5-D, extension of the four-dimensional (4-D) \(8\times 8\times 8\times 8\) 8 point approximate discrete cosine transform (ADCT) that has already appeared in the literature. Motivated by the partial separability of the multidimensional spectrum of Light Field Videos, the proposed 5-D ADCT is obtained by cascading 2-D inter-view, 2-D intra-view with 1-D time transform stages. Software simulations are provided to confirm the performance of the 5-D ADCT based compression.  

\end{abstract}

\begin{IEEEkeywords}

\end{IEEEkeywords}

\section{Introduction}

Total distribution of light models as seven-dimensional(7-D) function \(l(x,y,z,\theta,\phi,\lambda,t)\), which indicates light rays at every possible location in in space \(x,y,z)\) towards every possible direction \(\theta,\phi)\) over any range of wavelengths \(\lambda\) and at any time \(t\). However, due to huge amount of data to represent, it is necessary to make reasonable assumptions to reduce the dimensional. Normally Light rays of Light Field Videos do not change along direction of propagation. So one dimension in space can be removed Frequency \(\lambda\) is replaced with three colour channels and all three colour channel Light Field Videos are treated as independently. Thus Light Field Video is represented as five-dimensional(5-D) function \(l(x,y,\theta,\phi,t)\). To simplify Light Field Video representation, Each frame in Light Field Video can be represented in two parallel planes parameterization to represent in Cartesian coordinates, where one plane is camera plane \(XY\) and other plane is image plane \(UV\). Thus Light Field Video is represented as \(l(x,y,u,v,t)\), where \((x,y)\) are spatial dimension and \((u,v)\) are angular dimensions.

Light Field can acquire generally in three ways: Array of multiple cameras which arrange in linear, circular or even in arbitrary, Camera gantry which moves and capture different view points at different time instants and lens-let cameras which include an array of micro-lenses between the main lens and the image sensor. Light Field imaging has additional post capture processing capabilities notably Image refocusing, Depth filtering, Distance measurement, Changing lighting conditions etc. Thus widely applies in fields such as Virtual Reality (VR) and Augmented Reality (AR), sports broadcasting, personal communications, visual surveillance, medical imaging etc. Due to large volume of data captured in Light Field Video, it is difficult to process in real-time, mobile or web-based applications, where limited storage and bandwidth are required to store or transmit. Thus, fast and low-complexity compression techniques are needed to reduce number of bits required to process.

In this work, we propose a 5-D Light Field Video Lossy compression system, which is suitable for real-time compression of 5-D Light Field Videos, using 5-D type 2 discrete cosine transform (DCT) which has energy compaction property and widely used in data compression applications. The proposed system uses 8 point approximate DCT (ADCT) which are hardware efficient than exact DCT, leads to reduction in chip area and power consumption in digital VLSI hardware. By using 2-D partial separability, 5-D ADCT is obtained as a cascade of two 2-D ADCTs and one 1-D ADCT. Here first 2-D ADCT refers as intra-view transform where operations are done within Sub Aperture Images of particular frame, second 2-D ADCT refers as inter-view transform where operations are done across Sub Aperture Images of particular frame and 1-D ADCT operations are done across frames. Then obtained 5-D ADCT of a Light Field Video is subsequently treated as a collection of 5-D hyper-cubes of size \((8\times8\times8\times8\times8)\) and 5-D quantization happens, using constant \((8\times8\times8\times8\times8)\) matrix, on it to obtain compressed Light Field Video in 5-D DCT domain. 


\section{Related Work}
2-D Discrete Cosine Transform (2-D DCT) is widely used transform for image and video compression notably in JPEG, MPEG-1, MPEG-2, H.261, H.263, H.264, which has good energy compaction for images. JPEG 2000 and MPEG 4 Visual standards have used 2-D Discrete Wavelet Transform (2-D DWT) which provides high quality compression at low bit rates than 2-D DCT.  4-D Light Field compression is inspired from 2-D image compression where those techniques mentioned above applied in 2 ways. Earlier 4-D Light Field is divided as 3-D blocks along \(4^{th}\) dimension and 3-D DCT or 3-D DWT on it. Here 3-D blocks are treated as image stacks or pseudo video. Then 4-D DCT directly applies in Light Field which refers as Multidimensional Light Field Encoder (MuLE). where Light Field is divided into 4-D blocks and 1-D DCT is applied to each dimension separately. This is recently used in the JPEG Pleno Verification Model for lenslet Light Field compression. Same as 4-D DWT is applied to 4-D blocks of Light Field as cascade of four 1-D DWT. Karhunen Lo√®ve Transform (KLT) is another transform for Light Field compression where Micro Images (MI) are clustered using Vector Quantization (VQ) scheme, into a representative set of vectors which are used to coded with KLT. There is an alternative approach based on KLT where Sub Aperture Images (SAI) are used instead of Micro Images (MI). Both approaches give same performance but better than JPEG based but SAI are more easily decorrelated than MI. Graph Fourier Transform (GFT) is recently proposed transform for Light Field Video compression where graph based representation uses to model color, disparity or other geometry information from Light Field. Apart from these transforms, combinations of these transforms are proposed in literature notably 2-D DWT with 2-D DCT, 2-D DWT with KLT etc.

Apart from accuracy, reducing floating point operations which increase circuit complexity and power consumption, are main aim of doing compression in real time. To achieve this, approximate transforms are introduced and 8-point approximation DCT, 16-point approximation are proposed in literature. Generally DCT approximation matrices can be written as matrix multiplication of Diagonal matrix which contain only irrational numbers and low complexity matrix which contains only powers of two. Bouguezel introduces low complexity approximate in 2008 and that approximation DCT matrix can do matrix multiplication with \(8\times8\) block in 18 additions and 2 shifts but exact DCT needs 64 multiplications and 56 additions. In 2011, same team proposed another transform called Parametric transform, which arithmetic complexity is based on parameters \({0,1,2}\) and it increases when parameter value increases. Approximation matrix with parameter value 0 needs 16 additions. Same year another team proposed a matrix where low complexity matrix has only 0 and 1 to avoid shift operations but that approximation matrix needs 22 additions to do matrix multiplication. Then that team modified that matrix and proposed a new matrix which can multiply with \(8\times8\) block in 14 additions. Same as this another approximation matrix is proposed in 2014, which also needs 14 additions but it gives better output than previous one. Algorithms mentioned above are applied only in 2-D images, 3-D videos and 4-D Light Fields, to the best of my knowledge not applied for 5-D Light Field Videos.

\section{5-D ADCT Based LFV Compression}
Input to the proposed 5-D ADCT based Light Field Video Compression system is Light Field Video \(l(n)\), Here \(n \equiv (n_x,n_y,n_u,n_v,n_t) \in \mathbb{N}^5 \) denotes 5-D discrete spatial domain, \(n_x, n_y\) denotes point in camera plane, \(n_u, n_v\) denotes point in image plane and \(n_t\) denotes point in time axis. Based on standard two plane parameterization, size of Light Field Video is assumed as \((N_x,N_y,N_u,N_v,N_t)\). This size indicates there are \(N_x \times N_y\) SAIs, size of each SAI is \(N_u \times N_v\) pixels and \(N_t\) indicates number of frames in Light Field Video. Compression has been done in each channel separately. 

First step is partitioning all SAIs of particular time into \(8 \times 8\) blocks and applying Normalized 2-D DCT-2 on it. Let \(X\) be extracted \(8 \times 8\) block, whose entries are given by \(x[n_1,n_2]\) for \(n_1,n_2 = 1,2,...8\). 2-D DCT transformation of \(X\) is \(Y\), whose entries are given by:
\begin{multline*}
y[k_1,k_2] = a_N[k_1] \cdot a_N[k_2] \cdot \sum_{n_1=0}^{N-1} \sum_{n_2=0}^{N-1} x[n_1,n_2] \cdot \\ 
\cos{\left(\frac{\pi k_1(2n_1+1)}{2N}\right)} \cdot \cos{\left(\frac{\pi k_2(2n_2+1)}{2N}\right)}
\end{multline*}
where 
\[
    a_N[k] = \frac{1}{\sqrt{N}}
\begin{cases}
    1,& k_i = 0\\
    \sqrt{2},& k_i = 1,2,..,N-1
\end{cases}
\]
Here N = 8.
To solve equations efficiently, we can express this as:
\[Y = C_N \cdot X \cdot C_N^T \]
\(C_N\) entries are given by:
\[C_N[k,n] = a_N[k] \cdot \cos{\left(\frac{\pi k(2n+1)}{2N}\right)}\]
To achieve both null multiplier complexity and reduce adder complexity, instead of ideal DCT matrix \(C_N\), we use approximate DCT matrix \(\hat{C}_N\), which can be written as \(\hat{C}_N  = D_N \cdot T_N\). Here \(D_N\) is diagonal matrix with irrational numbers. This ADCT operation is repeated for all \(8 \times 8\) blocks in all SAIs for particular time. \(N_x \times N_y \times N_u/8 \times N_v/8 \times N_t\) no of operations are needed to complete intra-view ADCT transformation on entire Light Field Video and leads to create mixed domain 5-D signal \(L_1(n_x,n_y,k_u,k_v,n_t)\).

Next creating \(N_x\times N_y\) view points blocks from \(L_1(n_x,n_y,k_u,k_v,n_t)\) by changing pixel point across SAIs of particular time. Then partition that into \(8 \times 8\) blocks and apply Normalized 2-D DCT-2 on it. As mentioned earlier, To reduce complexity use Approximate DCT matrix \(\hat{C}_N\).This ADCT operation is repeated for all \(8\times8\) blocks across all SAIs for particular time. \(N_x/8\times N_y/8\times N_u\times N_v\times N_t\) no of operations are needed to complete inter-view ADCT transformation on entire Light Field Video and leads to create mixed domain 5-D signal \(L_2(k_x,k_y,k_u,k_v,n_t)\).

Next take points along time axis from \(L_2(k_x,k_y,k_u,k_v,n_t)\) for particular view point and pixel point. Then break that into dimension of \(8 \times 1\) vectors and apply Normalized 1-D DCT-2 on it. Let \textbf{x} be extracted \(8 \times 1\) vector, whose entries are given by \(x[n]\) for \(n = 1,2,...8\). 1-D DCT transformation of \textbf{x} is \textbf{y}, whose entries are given by:
\[y[k] = a_N[k] \cdot \sum_{n=0}^{N-1} x[n] \cdot \cos{\left(\frac{\pi k(2n+1)}{2N}\right)} \]
where 
\[
    a_N[k] = \frac{1}{\sqrt{N}}
\begin{cases}
    1,& k_i = 0\\
    \sqrt{2},& k_i = 1,2,..,N-1
\end{cases}
\]
Here N = 8.
To solve equations efficiently, we can express this as:
\[Y = C_N \cdot X \]
\(C_N\) entries are given by:
\[C_N[k,n] = a_N[k] \cdot \cos{\left(\frac{\pi k(2n+1)}{2N}\right)}\]
To reduce complexity, we can use approximate DCT matrix \(\hat{C}_N\) instead of ideal DCT matrix \(C_N\).This ADCT operation is repeated for all \(8 \times 1\) vectors along time axis for particular view point and pixel point. \(N_x \times N_y \times N_u \times N_v \times N_t/8\) no of operations are needed to complete 1-D ADCT transformation on entire Light Field Video and create fully transformed 5-D signal \(L(k_x,k_y,k_u,k_v,k_t)\).

Next apply 5-D Quantization on \(L(\textbf{k})\) to discard high frequency components. \(8 \times 8 \times 8 \times 8 \times 8\) constant value matrix \(Q(k)\) is used in Quantization process. Output of Quantization process is expressed as:
\[L_q(k) = round \left( \frac{L(k)}{Q(k)} \right) \cdot Q(k)\]
where both the division and multiplication of the matrices are element wise. After quantization process, ADCT coefficients higher than threshold value are only retained, leading to lossy Light Field Video compression.

\section{Performance Analysis}
To measure performance of Light Field Video compression, three Light Field Videos were used : Car, David, Toy. All three Light Field Videos were made from \(15\times15\) views of videos. For our processing \(8\times8\) views were taken and all SAIs are in YUV420 format. Table \ref{table:DatasetsSpecification} summarizes size, minimum and maximum value of each data set channel.

\begin{table}
\begin{center}
\caption{Data Set Specification}
\label{table:DatasetsSpecification}
\begin{tabular}{|c c c c c|} 
 \hline
 Dataset & Channel & Size & Min & Max \\ [0.5ex] 
 \hline\hline
 Car & U & \(8\times8\times176\times256\times24\) & 25 & 181\\
 \hline
 & V & \(8\times8\times176\times256\times24\) & 80 & 193\\
 \hline
 & Y & \(8\times8\times352\times512\times24\) & 3 & 255\\
 \hline\hline
 David & U & \(8\times8\times160\times240\times24\) & 49 & 122\\
 \hline
 & V & \(8\times8\times160\times240\times24\) & 107 & 151\\
 \hline 
 & Y & \(8\times8\times320\times480\times24\) & 43 & 229\\
 \hline\hline
 Toy & U & \(8\times8\times160\times240\times24\) & 3 & 160 \\ 
 \hline
 & V & \(8\times8\times160\times240\times24\) & 50 & 224 \\ 
 \hline
 & Y & \(8\times8\times320\times480\times24\) & 12 & 255\\ [0.5ex] 
 \hline
\end{tabular}
\end{center}
\end{table}

Quality of compressed Light Field Video is measured by using Peak
Signal to Noise Ratio (PSNR) and Structural Similarity Index for Measuring image quality (SSIM) of each SAI. The PSNR between the original SAI A and the reconstructed SAI A‚Äô is computed as follows:
\[PSNR = 10\log_{10}\left( \frac{2^n - 1}{MSE} \right)\]
Where n is no of bits in SAI and MSE between the two M√óN SAIs A and A‚Äô is given by:
\[MSE = \left(\frac{1}{M\times N} \right)\sum_{i=0}^{M-1} \sum_{j=0}^{N-1}(A(i,j)-A'(i,j))^2\]
The SSIM between the original SAI A and the reconstructed SAI A‚Äô is computed as follows:
\[SSIM = \frac{(2\mu_A\mu_{A'}+C_1)(2\sigma_{AA'}+C_2)}{(\mu_A^2+\mu_{A'}^2+C_1)(\sigma_A^2+\sigma_{A'}^2+C_2)}\]
Where \(\mu_A,\mu_{A'},\sigma_A,\sigma_{A'},,\sigma_{AA'}\) are local means, standard deviations, and cross covariance for SAIs A, A'. The PSNR and SSIM for Light Field Video are computed by averaging the PSNRs and SSIMs of SAIs individually. The \(SSIM_{YCbCr}\) is computed using only the luminance component (Y). But \(PSNR_{YCbCr}\) is computed by using \(PSNR_Y, PSNR_{Cb}\) and \(PSNR_{Cr}\) as follows:
\[PSNR_{YCbCr} = \frac{6*PSNR_Y + PSNR_{Cb} + PSNR_{Cr}}{8}\]

\begin{figure*}
\begin{center}
\includegraphics[width=\textwidth]{results/psnrvsbpp.eps}
\caption{PSNR vs Compression rate on different ADCT algorithms Exact DCT, BAS-2008, BAS-2011 for parameter 0, BAS-2011 for parameter 1, CB-2011, Modified CB-2011 and PMC 2014 in 5-D domain for data set (a) Car (b) David (c) Toy.}
\label{fig:bppvspsnr}
\end{center}
\end{figure*}

In Fig. \ref{fig:bppvspsnr}(a)-(c), PSNR is plotted against bits per pixel for different ADCT algorithms. When decreasing compressed Light Field Video bits per pixel, PSNR is also decreasing and at one point it is converging. All 7 PSNR vs Compression rate graphs are nearly same for all 3 data sets. For data set Car and Toy, PSNR converges near to 41dB and bits per pixel values starts at near to 0.6. For data set David, PSNR converges near to 45dB and bits per pixel values starts at near to 0.3. As explained in Table \ref{table:DatasetsSpecification}, data set David has small range values than other data sets. This is the reason for that particular data set getting better PSNR values for small Compression rate values too.

\begin{figure*}
\begin{center}
\includegraphics[width=\textwidth]{results/ssimvsbpp.eps}
\caption{SSIM vs Compression rate on different ADCT algorithms Exact DCT, BAS-2008, BAS-2011 for parameter 0, BAS-2011 for parameter 1, CB-2011, Modified CB-2011 and PMC 2014 in 5-D domain for data set (a) Car (b) David (c) Toy.}
\label{fig:bppvsssim}
\end{center}
\end{figure*}

In Fig. \ref{fig:bppvsssim}(a)-(c), SSIM is plotted against Compression rate  for different ADCT algorithms. All 7 SSIM vs Compression rate  graphs are nearly same for all 3 data sets. From these, assumption can be taken as final outputs will not be differed when using different ADCT matrices. Here none of the values are less than 0.9. From these, assumption can be taken as compression does not loose information that much. Table \ref{table:qval} explains when changing value in constant quantization matrix how compression rate, PSNR, SSIM, energy retained are changing. For this experiment Y channel of data set David is selected. When you are increasing value, at one point retained energy rate is reduced but compression rate, PSNR and SSIM converge.

\begin{table}
\begin{center}
\caption{Quantization}
\label{table:qval}
\begin{tabular}{|c|c|c|c|c|} 
 \hline
 \shortstack{\\Quantization \\ value} & \shortstack{\\Compression \\ rate [bpp]}  & PSNR [dB] & SSIM & \shortstack{\\Energy \\ retained} \\ [0.5ex] 
 \hline\hline
 1 & 1.33 & 62.32 & 1 & 1\\
 \hline
 3 & 0.47 & 55.26 & 0.99 & 1\\
 \hline
 5 & 0.28 & 53.53 & 0.99 & 1\\
 \hline
 7 & 0.2 & 52.41 & 0.99 & 1\\
 \hline
 10 & 0.14 & 51.26 & 0.99 & 0.99\\
 \hline 
 15 & 0.09 & 50.06 & 0.98 & 0.99\\
 \hline
 25 & 0.06 & 48.76 & 0.98 & 0.98 \\ 
 \hline
 35 & 0.04 & 48.06 & 0.97 & 0.97 \\ 
 \hline
 50 & 0.04 & 47.44 & 0.97 & 0.96\\ 
 \hline
 80 & 0.03 & 46.67 & 0.97 & 0.95\\
 \hline 
 100 & 0.03 & 46.31 & 0.97 & 0.95\\
 \hline
 120 & 0.03 & 45.97 & 0.96 & 0.95 \\ 
 \hline
 150 & 0.03 & 45.65 & 0.96 & 0.94 \\ 
 \hline
 180 & 0.03 & 45.25 & 0.96 & 0.94\\  
 \hline
 200 & 0.03 & 44.99 & 0.96 & 0.94\\ [0.5ex] 
 \hline
\end{tabular}
\end{center}
\end{table}

\section{Conclusion}
In this paper Light Field Video compression is proposed using 5-D DCT. To reduce arithmetic complexity, 8 point approximate DCT is used instead of exact DCT. Proposed system first change Light Field Video in 5-D frequency domain by doing following sequentially : 2-D intra view compression, 2-D inter view compression and 1-D compression along time axis. Then doing quantization on it by breaking Light Field Video into \(8\times8\times8\times8\times8\) size blocks and compressed Light Field Video is obtained. Here Light Field Video used in YUV420 format and compression done for all three channels separately. At end of this paper, SSIM and PSNR is calculated between original Light Field Video and reconstructed Light Field Video for different datasets and different approximate 8 point 2-D DCT algorithms which are already published in literature. Thus we could get minimum 43 dB average PSNR and 0.91 average SSIM and these indicate our compression algorithm is efficient and we do not loose that much information while compressing. Future work includes 5-D Light Field Video compression implementation in FPGA device and 5-D Light Field Video reconstruction algorithm development using prediction modelling. 


\begin{thebibliography}{00}
\bibitem{b1} U. S. Potluri, A. Madanayake, R. J. Cintra, F. M. Bayer, S. Kulasekera, and A. Edirisuriya, ‚ÄúImproved 8-point Approximate DCT for Image and Video Compression Requiring Only 14 Additions,‚Äù IEEE Trans. Circuits Syst. I, Reg. Papers, vol. 61, no. June, pp. 1727‚Äì1740, jun 2014.

\end{thebibliography}


\end{document}
